{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 13:33:55.834885: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 13:33:55.977330: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-06 13:33:55.977371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-06 13:33:55.978498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 13:33:56.051607: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 13:33:56.053190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 13:33:57.030198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Conv2D, MaxPooling2D,\n",
    "    Activation, Flatten, Dropout, Dense\n",
    ")\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "INIT_LR = 1e-3\n",
    "BS = 64\n",
    "default_image_size = (64, 64)\n",
    "directory_root = '/home/raj/Documents/project/plantvillage'\n",
    "depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, default_image_size)\n",
    "            return image.astype(np.float16) / 255.0\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "[INFO] Processing Tomato__Target_Spot ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Pepper__bell___healthy ...\n",
      "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
      "[INFO] Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Tomato__Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato_Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato_healthy ...\n",
      "[INFO] Processing Tomato_Early_blight ...\n",
      "[INFO] Processing Tomato_Late_blight ...\n",
      "[INFO] Processing Tomato_Bacterial_spot ...\n",
      "[INFO] Processing Tomato_Leaf_Mold ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "image_list, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    for directory in root_dir:\n",
    "        if directory == \".DS_Store\":\n",
    "            root_dir.remove(directory)\n",
    "    for plant_folder in root_dir:\n",
    "        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "        for disease_folder in plant_disease_folder_list:\n",
    "            if disease_folder == \".DS_Store\":\n",
    "                plant_disease_folder_list.remove(disease_folder)\n",
    "        for plant_disease_folder in plant_disease_folder_list:\n",
    "            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n",
    "            for single_plant_disease_image in plant_disease_image_list[:200]:\n",
    "                if single_plant_disease_image.endswith(\".jpg\") or single_plant_disease_image.endswith(\".JPG\"):\n",
    "                    image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{single_plant_disease_image}\"\n",
    "                    image_list.append(convert_image_to_array(image_directory))\n",
    "                    label_list.append(plant_disease_folder)\n",
    "    print(\"[INFO] Image loading completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "pickle.dump(label_binarizer, open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_image_list = np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 13:36:08.843855: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), padding=\"same\", input_shape=(64, 64, 3)),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(3, 3)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1024),\n",
    "    Activation(\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_classes),\n",
    "    Activation(\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64, 64, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 21, 21, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 21, 21, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 21, 21, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 21, 21, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 21, 21, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 21, 21, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 10, 10, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10, 10, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 10, 10, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              3277824   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                15375     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 15)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3576719 (13.64 MB)\n",
      "Trainable params: 3573839 (13.63 MB)\n",
      "Non-trainable params: 2880 (11.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training network...\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] Training network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 12s 275ms/step - loss: 2.6961 - accuracy: 0.3134 - val_loss: 3.7179 - val_accuracy: 0.0558\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 8s 229ms/step - loss: 1.5895 - accuracy: 0.5282 - val_loss: 8.9720 - val_accuracy: 0.0558\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 7s 202ms/step - loss: 1.3131 - accuracy: 0.6020 - val_loss: 11.4236 - val_accuracy: 0.0558\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 1.0955 - accuracy: 0.6589 - val_loss: 19.0943 - val_accuracy: 0.0558\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.9431 - accuracy: 0.6944 - val_loss: 17.5376 - val_accuracy: 0.0558\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 7s 194ms/step - loss: 0.8346 - accuracy: 0.7305 - val_loss: 19.1312 - val_accuracy: 0.0558\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.8154 - accuracy: 0.7435 - val_loss: 14.8394 - val_accuracy: 0.0558\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 7s 198ms/step - loss: 0.6962 - accuracy: 0.7674 - val_loss: 13.8080 - val_accuracy: 0.0558\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 7s 199ms/step - loss: 0.7092 - accuracy: 0.7617 - val_loss: 11.2870 - val_accuracy: 0.0998\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 9s 249ms/step - loss: 0.6645 - accuracy: 0.7808 - val_loss: 10.8855 - val_accuracy: 0.1049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Calculating model accuracy\")\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1] * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Saving model...\")\n",
    "pickle.dump(model, open('cnn_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
